# Azure AI Custom Vision – Object Detection

## Overview
- Object detection = identifying:
  - What objects are in an image
  - Where they are located
- Each prediction includes:
  - Class label (what the object is)
  - Bounding box (where the object is)

## Common Use Cases
- Automated retail checkout
- Surveillance and monitoring
- Traffic analysis
- Manufacturing defect detection
- Robotics and autonomous systems

## Azure AI Custom Vision for Object Detection
- Used to build **custom object detection models**
- Requires **two Azure resources**:
  - Training resource
  - Prediction resource

## Required Azure Resources
### Training Resource
- Used to:
  - Upload and label images
  - Train object detection models
  - Evaluate performance
- Typically used during development

### Prediction Resource
- Used to:
  - Host published models
  - Perform inference on new images
- Used by production applications

## Resource Separation Benefits
- Train in one region, predict in another
- Scale prediction independently
- Reduce latency for end users

## Custom Vision Portal
- Web UI: https://www.customvision.ai/
- Used to:
  - Create object detection projects
  - Upload and label images
  - Train and test models
  - Publish models
- Each project has a **unique Project ID**

## Object Detection vs Image Classification
### Image Classification
- One or more labels per image
- No location information
- Example: “This image contains fruit”

### Object Detection
- Multiple objects per image
- Location of each object included
- Example: “Apple here, banana there”

## Object Detection Predictions
Each detected object includes:
- tag_name (class label)
- probability (confidence score)
- bounding_box:
  - left
  - top
  - width
  - height

## Training an Object Detection Model
### Key Difference: Labeling
- Image classification:
  - Tags apply to entire image
- Object detection:
  - Tags + bounding boxes per object

### Bounding Box Format
- Values are **relative (0–1)** to image size
- Defined by:
  - left (X of top-left corner)
  - top (Y of top-left corner)
  - width
  - height

### Example Bounding Box
- left: 0.1
- top: 0.5
- width: 0.5
- height: 0.25

## Labeling Images
### Portal Labeling
- Draw bounding boxes around objects
- Assign tag to each box
- Portal can:
  - Suggest regions
  - Enable smart labeler after initial training

### Smart Labeler
- Requires:
  - Initial set of labeled images
  - At least one trained object detection model
- Can suggest:
  - Object regions
  - Object classes

### Alternative Labeling
- Third-party or custom tools
- Must convert bounding boxes to:
  - Relative (proportional) values
- Often exported as JSON

## Training Workflow
1. Create object detection project
2. Upload images
3. Label objects with bounding boxes
4. Train model
5. Evaluate results
6. Improve labels if needed
7. Publish model

## Developing an Object Detection Client App
### Required Information
- Prediction endpoint
- Prediction key
- Project ID
- Published model name

### Prediction Output
- Multiple predictions per image
- Each includes:
  - Object label
  - Confidence score
  - Bounding box coordinates

### Typical App Logic
- Apply confidence threshold (example: > 0.5)
- Draw boxes or take action based on detections

## Key Differences: Detection vs Classification Models
- Detection models:
  - Slower inference than classification
  - More complex training
  - Richer output (location + label)
- Classification models:
  - Faster
  - Simpler labeling
  - No spatial data

## Module Assessment – Answers
1. What does an object detection model predict?
   - The location and class of specific classes of object in an image

2. Requirement before using smart labeler?
   - Tag some images with objects of each class and train an initial object detection model
