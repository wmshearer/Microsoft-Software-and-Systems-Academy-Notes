# Fine-tuning language models in Microsoft Foundry

## Why fine-tune instead of training from scratch
Base/foundation language models are pretrained and provide a strong starting point, reducing the time, data, and compute required to adapt a model to a specific use case. Fine-tuning is presented as a strategy for aligning a model’s responses with a desired format, style, and tone (for example, a company’s “tone of voice”) while needing less effort than building a new model from scratch.

## When to fine-tune vs other optimization strategies
When building a chat application in Microsoft Foundry, prompt flow can integrate a language model to generate responses. To improve response quality, the module describes an escalation path of strategies:

### Prompt engineering (first)
Prompt engineering improves model output by adjusting how prompts are written and by updating the system message that accompanies the user prompt. It is quick and easy for guiding how the model should respond and what it should consider.

A prompt-engineering technique for formatting consistency is one-shot/few-shot prompting, where you provide one or more examples of desired output patterns. However, the module notes that even with strong prompting, the model may not behave consistently and may ignore instructions.

### Retrieval Augmented Generation (RAG)
RAG is most commonly used when responses must be factual and grounded in specific data by retrieving context from a data source before generation.

### Fine-tuning (for consistency of behavior)
Fine-tuning is used when you want the model to behave a certain way consistently, especially for style, format, and tone. If prompt engineering (even with one-shot/few-shot examples) does not produce consistent adherence to your desired behavior, fine-tuning a base model on your training data is used to maximize behavioral consistency.

Fine-tuning and RAG can be combined (for example: RAG for factual grounding + fine-tuning for consistent tone/format).

# Preparing data to fine-tune a chat completion model

## What fine-tuning uses
Fine-tuning combines:
- A suitable base/foundation model
- Training data containing example prompts and responses that represent ideal behavior

The quality and diversity of the dataset strongly influences fine-tuned model quality. While less data is needed than training from scratch, you may still need enough examples to achieve consistent desired behavior, depending on the use case.

## Chat completion fine-tuning dataset format (required components)
For chat completion fine-tuning, training data is a collection of sample conversations with three required components:
- System message
- User message
- Assistant response

The dataset is stored in JSON Lines (JSONL) format, where each line is a JSON object containing the conversation messages. Example format: `{"messages":[{"role":"system","content":"..."},{"role":"user","content":"..."},{"role":"assistant","content":"..."}]}`

## Building the dataset (quality and safety)
If using real chat history as training data:
- Remove personal or sensitive information
- Ensure diversity and coverage of scenarios (don’t only maximize volume)
The dataset should represent the model’s ideal behavior for your application.

## Multi-turn conversations and message weighting
A single JSONL line can include multiple turns of conversation. You can optionally use a weight key-value pair to include or ignore specific assistant messages during training:
- `weight: 0` ignores the message for training
- `weight: 1` includes the message for training

Example pattern: multi-turn messages in one line, with `{"role":"assistant","content":"...","weight":1}` on the assistant messages you want to train on.

# Fine-tuning in the Microsoft Foundry portal

## Selecting a base model
Microsoft Foundry model catalog contains foundation models that can be fine-tuned for tasks like text classification, translation, or chat completion. For a chat app, you select a base model that supports fine-tuning for chat completion and filter the catalog by fine-tuning task.

Examples of models mentioned as options: GPT-4 and Llama-2-7b (availability depends on quota and region).

### Considerations when choosing a foundation model
When selecting a model to fine-tune, consider:
- Model capabilities and alignment to task (example given: BERT better at understanding short texts)
- Pretraining data characteristics (example given: GPT-2 trained on unfiltered internet content, potential bias)
- Known limitations and biases
- Language support and multilingual requirements
Model cards (referenced in Foundry and hosted on Hugging Face) provide deeper details.

## Configuring a fine-tuning job (portal workflow)
Portal steps to configure a fine-tuning job:
- Select base model
- Select training data
- (Optional) Select validation data
- Configure advanced options

After submission, a training job runs. You can monitor job status and review input parameters after completion. If validation data is provided, you can review performance on the validation dataset. You can deploy the fine-tuned model, test it, and then integrate it into the chat application.

## Advanced options described
- batch_size: number of training examples per forward/backward pass; larger batch sizes often work better for larger datasets; larger batch size updates parameters less frequently with lower variance; defaults and max depend on base model
- learning_rate_multiplier: fine-tuning learning rate is pretraining learning rate multiplied by this value; larger learning rates tend to work better with larger batch sizes; suggested experimentation range 0.02–0.2; smaller values can help avoid overfitting
- n_epochs: number of epochs; one epoch is one full cycle through the training dataset
- seed: controls reproducibility; same seed + parameters should produce the same results (rare exceptions); generated automatically if not provided

# Module assessment answers

## Q1: How must data be formatted for fine-tuning?
Answer: JSONL

## Q2: What does fine-tuning optimize in your model?
Answer: How the model needs to act.

## Q3: Which advanced option refers to one full cycle through the training dataset?
Answer: n_epochs
