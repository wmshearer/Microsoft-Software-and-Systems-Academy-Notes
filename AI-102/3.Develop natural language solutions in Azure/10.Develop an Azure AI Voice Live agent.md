# Azure AI Voice Live API

## Overview
- Voice Live API enables **real-time, bidirectional speech-to-speech** interactions.
- Designed for **low-latency voice agents** without manually orchestrating:
  - Speech-to-text
  - LLM inference
  - Text-to-speech
- Uses **WebSocket-based streaming** with event-driven control.

## Core Capabilities
- Real-time speech recognition
- Real-time speech synthesis
- Speech-to-speech conversations
- Avatar streaming (audio + video)
- Noise reduction & echo cancellation
- Multiple audio formats (PCM16, G.711)

## Architecture
- Communication over **WebSocket (wss://)**
- Conversation controlled via **JSON events**
- Two event categories:
  - Client events (client → server)
  - Server events (server → client)

## Authentication Methods
- Supported methods:
  - Microsoft Entra ID (keyless) ✅ recommended
  - API key
- Entra authentication:
  - Token-based
  - Requires Cognitive Services User role
  - Token scope:
    - https://ai.azure.com/.default
    - (legacy) https://cognitiveservices.azure.com/.default
- API key options:
  - api-key header (not supported in browsers)
  - api-key query parameter (wss encrypted)

## WebSocket Endpoints
- Project connection:
  wss://<resource>.services.ai.azure.com/voice-live/realtime?api-version=2025-10-01
- Model connection:
  wss://<resource>.cognitiveservices.azure.com/voice-live/realtime?api-version=2025-10-01
- Same endpoint for all models
- Model selected via query param or agent_id + project_id

## Voice Live API Events

### Client Events
- session.update
  - Configure session behavior
- input_audio_buffer.append
  - Add audio chunks
- input_audio_buffer.commit
  - Process buffered audio
- input_audio_buffer.clear
  - Reset buffer
- response.create
  - Trigger model response
- session.avatar.connect
  - Start avatar streaming

### Server Events
- session.updated
  - Session config applied
- conversation.item.created
  - New conversation item
- response.audio.delta
  - Streaming audio output
- response.done
  - Response completed
- input_audio_buffer_speech_started
  - User started speaking
- error
  - Error notification

## Session Configuration
- Usually first event: session.update
- Configurable settings:
  - Modalities (text, audio)
  - Voice (OpenAI or Azure)
  - Instructions (system prompt)
  - Input/output audio formats
  - Turn detection (VAD)
  - Temperature
  - Token limits

## Turn Detection (VAD)
- Recommended:
  - azure_semantic_vad
- Key parameters:
  - threshold
  - prefix_padding_ms
  - silence_duration_ms
- Improves conversational flow and latency

## Audio Processing
- Audio buffer lifecycle:
  - Append → Commit → Clear
- Optional enhancements:
  - Noise reduction:
    - azure_deep_noise_suppression
  - Echo cancellation:
    - server_echo_cancellation
- Improves transcription accuracy and VAD behavior

## Avatar Streaming
- Uses **WebRTC**
- Supports:
  - Video streaming
  - Facial animation
  - Blendshapes
  - Visemes
- Requires:
  - session.avatar.connect event
  - Client SDP offer

## Python Voice Live Client SDK
- Async-only (sync deprecated)
- Opens WebSocket session
- Streams microphone audio
- Receives server events

## Authentication in Python SDK
- API key:
  `AzureKeyCredential("API_KEY")`
- Entra (recommended):
  `DefaultAzureCredential()`

## Event Handling Best Practices
- Must handle interrupts correctly
- When user speaks:
  - Stop audio playback immediately
  - Cancel current response
- Prevents agent talking over user

## Minimal Session Flow
- Connect to endpoint
- Authenticate
- Send session.update
- Stream audio
- Handle server events
- Generate responses

## Key Takeaways
- Voice Live API = real-time speech-to-speech
- WebSocket + event-driven architecture
- Microsoft Entra auth preferred for production
- Proper event handling is critical for UX
- Avatar streaming uses WebRTC

## Module Assessment – Answers
1. Supported authentication methods?
   - Microsoft Entra (keyless) and API key

2. Required Entra token scope?
   - https://cognitiveservices.azure.com/.default

3. Protocol for avatar streaming?
   - WebRTC

4. Event to stop playback on user interrupt?
   - ServerEventType.INPUT_AUDIO_BUFFER_SPEECH_STARTED

5. Recommended production authentication?
   - Microsoft Entra authentication with DefaultAzureCredential
