# Azure Language — Question Answering (Condensed Notes)

## What is Question Answering
Question Answering (QA) lets users ask **natural language questions** and receive **direct answers** from a predefined **knowledge base (KB)**.

Core idea:
- User asks a question
- Service matches it to the **closest known question**
- Returns a **static answer** with a confidence score

Common use cases:
- FAQ bots
- Helpdesk / support portals
- Knowledge-driven chatbots

Knowledge bases can be built from:
- FAQ web pages
- Documents (PDFs, guides, manuals)
- Built-in chit-chat datasets (casual conversation)

---

## Question Answering vs Language Understanding
These services solve **different problems** and are often used together.

### Question Answering
- Input: **Question**
- Output: **Answer**
- Logic: Match question → return static response
- Client app: Displays answer

### Language Understanding
- Input: **Utterance**
- Output: **Intent + entities**
- Logic: Interpret meaning → decide what action to take
- Client app: Executes logic based on intent

Rule of thumb:
- Use **Question Answering** when the user wants information
- Use **Language Understanding** when the user wants something done

---

## Create a Knowledge Base
Most commonly done using **Language Studio** (UI-based).

High-level steps:
1. Create an **Azure Language resource**
2. Enable **Question Answering**
3. Create or link an **Azure AI Search** resource
4. In Language Studio:
   - Create a **Custom Question Answering project**
   - Add data sources:
     - URLs
     - Files
     - Chit-chat datasets
5. Edit and refine Q&A pairs

---

## Multi-Turn Conversation
Multi-turn allows **follow-up questions** when the initial question is ambiguous.

Example:
- Q: “How do I cancel a reservation?”
- Follow-up prompts:
  - “Cancel a hotel”
  - “Cancel a flight”

Key points:
- Follow-ups can link to existing answers or new ones
- Answers can be restricted to **only appear in that conversation flow**
- Useful when clarification is required before answering

---

## Test and Publish
After creating the KB:
- **Train** the model
- **Test** interactively in Language Studio
  - View confidence scores
  - Inspect alternate matches
- **Publish** the KB
  - Exposes a REST endpoint for apps and bots

---

## Use a Knowledge Base (API)
Clients query the KB via REST.

Key request properties:
- `question`: user input
- `top`: max answers returned
- `scoreThreshold`: minimum confidence
- `strictFilters`: metadata-based filtering

Example concept (inline only):
`POST /knowledgebases/{id}/generateAnswer`

Response includes:
- Best-matching question
- Answer text
- Confidence score
- Metadata

---

## Improve Question Answering Performance

### Active Learning
Helps the KB learn **alternate phrasings** over time.

How it works:
- Service suggests alternate questions
- You review and **accept or reject**
- Improves matching accuracy

Active learning:
- Enabled by default
- Managed in **Review suggestions** pane

---

### Synonyms
Maps different words with the **same meaning**.

Example:
- “reservation” ↔ “booking”

Defined using REST (conceptually):
`"synonyms": ["reservation", "booking"]`

Benefits:
- Better matching
- Fewer missed answers
- Improved user experience

---

# Module Assessment — Answers

## 1) Create a knowledge base from an existing FAQ document
✅ **Create a new knowledge base, importing the existing FAQ document.**

## 2) Add multi-turn context to an existing question
✅ **Add a follow-up prompt to the question.**

## 3) Enable users to access the knowledge base via email
✅ **Create a bot based on your knowledge base and configure an email channel.**
