# Azure AI Search – Condensed Notes (Knowledge Mining Focus)

## What Azure AI Search Does
- Cloud service for:
  - Indexing + querying data from many sources
  - Enriching content with AI skills (knowledge mining)
  - Persisting enriched outputs via Knowledge Store
- Common use cases:
  - Enterprise search
  - Knowledge mining (extract insights from docs)
  - RAG (vector indexes) — mentioned, but module focuses on knowledge mining

## Core Components (Pipeline)
- Data Source → Indexer (+ Skillset) → Index → Query
                          ↘ Knowledge Store (optional)

### Data Source
- Where your raw data lives:
  - Blob storage (common)
  - Databases
  - Other supported stores

### Index
- Collection of JSON docs containing searchable fields + enriched fields

### Indexer (the “scheduled worker”)
- Automates:
  - Extracting content from data source (document cracking)
  - Running enrichment pipeline (skills)
  - Mapping outputs into the index
- Can also generate Knowledge Store projections

## How Index Documents Are Built (Important Concept)
- Each indexed item becomes a hierarchical JSON document
- Starts with extracted fields like:
  - metadata_storage_name
  - metadata_author
  - content
- If docs contain images, indexer can create:
  - normalized_images[] (image0, image1, …)
- Skills write new fields into the hierarchy, like:
  - language
  - normalized_images[i].Text (from OCR)
  - merged_content (merge original + OCR text)

## Field Mappings (Two Types)
1) Source fields → index fields
   - Implicit (same name) or explicit mapping (rename/transform)
2) Skill outputs → index fields
   - Explicit mapping from hierarchical path → target index field

## AI Enrichment with Skillsets
### Built-in skills (from Foundry Tools integrations)
Examples:
- Language detection
- Entity extraction
- Key phrase extraction
- Translation
- PII detection/removal
- OCR (read text from images)
- Image captions/tags

**Requirement:** indexer needs access to a Foundry Tools resource for built-in skills  
- Must be in the **same region** as the Azure AI Search resource
- There’s also a limited built-in option (restricted Azure AI Search resource) for small indexing (≤20 docs)

### Custom skills
- Your code (often an Azure Function) that takes input fields and returns new fields
- Example use: call Azure Document Intelligence to extract fields from forms

## Querying an Index
### Index field attributes (know these)
- key: unique identifier
- searchable: full-text search enabled
- filterable: usable in filters
- sortable: usable in ordering results
- facetable: usable for facets in UI
- retrievable: returned in results (default yes unless disabled)

### Full-text search
- Uses Lucene-based syntax:
  - Simple (easier literal search)
  - Full (advanced queries, regex, etc.)

### Common query parameters
- search: the text expression
- queryType: simple | full
- searchFields: which fields to search
- select: which fields to return
- searchMode:
  - Any (OR logic)
  - All (AND logic)

### Query processing stages (high-level)
1) Parse query (terms, phrases, prefixes)
2) Lexical analysis (lowercase, stopwords removed, stemming)
3) Retrieve matching docs
4) Score (TF/IDF relevance)

## Filtering + Facets + Sorting
### Filtering
- Simple syntax can embed filters
- Full syntax can use **OData $filter**
- IMPORTANT: **$filter is case-sensitive**

Example (full syntax):
- search=London
- $filter=author eq 'Reviewer'
- queryType=Full

### Facets (UI-friendly filters)
- Only works on **facetable** fields
- First query to get facet values:
  - search=*
  - facet=author
- Next query filters using selected value:
  - $filter=author eq 'someValue'

### Sorting
- Default: relevance score
- Override with OData $orderby on sortable fields
  - $orderby=last_modified desc

## Knowledge Store (Persist Enriched Data)
- Optional output from the enrichment pipeline
- Stores “projections” of enriched data for reuse:
  - Objects (JSON-like)
  - Tables (relational schema)
  - Files (including images)
- Useful when you want enriched outputs outside the search index (ETL, reporting, analytics)

## Azure OpenAI On Your Data – Retrieval Configuration & Flow (Practice Test Notes)

### Retrieval Configuration Parameters
- Strictness
  - Controls relevance threshold during retrieval
  - Higher value = fewer, more relevant documents returned
  - Filters out low-relevance content before response generation

- Retrieved documents
  - Specifies how many top-scoring documents/chunks are pulled from Azure AI Search
  - Directly impacts grounding context size for the LLM

- Content data
  - Defines which index fields contain the main textual content
  - These fields are used for chunking, embedding, and grounding responses

- File name
  - Specifies the index field containing the original document name
  - Useful for citations, traceability, and response attribution

### Azure OpenAI On Your Data – End-to-End Flow
- Ingest
  - Upload files via Foundry portal or ingestion API
  - Data is cracked, chunked, and embedded
  - Stored in Azure AI Search (or connected directly from supported sources)

- Develop
  - Build the application using REST APIs or SDKs
  - Prompts and search intents are generated and sent to Azure OpenAI

- Inference (runtime execution)
  - Intent generation
    - Service determines the user’s intent from the prompt
  - Retrieval
    - Relevant chunks retrieved using semantic or vector search
    - Influenced by strictness and number of retrieved documents
  - Filtration and reranking
    - Retrieved results are ranked and filtered to improve relevance
  - Response generation
    - Filtered data + system message sent to the LLM
    - Final grounded response returned to the application


# The development process you'd use with Azure OpenAI On Your Data is:

## Module Assessment – Answers
1) Component scheduled to extract + enrich data to populate an index:
- Indexer

2) Service that supports built-in AI skills in Azure AI Search:
- Foundry Tools

3) Projection type that results in relational data schema:
- Table
